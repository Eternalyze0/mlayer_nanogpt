# mlayer_nanogpt
nanoGPT but with MLPs replaced by M-layers: https://arxiv.org/pdf/2008.03936.

mlayer:

step 2000: train loss 1.6256, val loss 1.7869

vs baseline:

step 2000: train loss 1.7648, val loss 1.8857

these numbers are for char-level but a similar 0.1 difference exists for token-level
