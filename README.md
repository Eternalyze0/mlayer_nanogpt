# M-Layer nanoGPT
nanoGPT but with MLPs replaced by M-layers: https://arxiv.org/pdf/2008.03936.
```
mlayer:
step 2000: train loss 1.5898, val loss 1.7110
vs baseline:
step 2000: train loss 1.7648, val loss 1.8857
```
these numbers are for char-level but a similar 0.1 difference exists for token-level
